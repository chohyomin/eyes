import cv2
import numpy as np
import mediapipe as mp
import pickle

# âœ… ì˜ˆì¸¡í•  ì˜ìƒ ê²½ë¡œ
VIDEO_PATH = 'test_videos/test_pass1.mp4'  # ì—¬ê¸°ë¥¼ ì›í•˜ëŠ” íŒŒì¼ëª…ìœ¼ë¡œ ë°”ê¾¸ì„¸ìš”

# âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
with open('pose_classifier.pkl', 'rb') as f:
    clf = pickle.load(f)

# MediaPipe ì´ˆê¸°í™”
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)
mp_drawing = mp.solutions.drawing_utils

cap = cv2.VideoCapture(VIDEO_PATH)

keypoints_all = []

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(image_rgb)

    if results.pose_landmarks:
        landmarks = results.pose_landmarks.landmark
        keypoints = []
        for lm in landmarks:
            keypoints.extend([lm.x, lm.y, lm.z, lm.visibility])
        keypoints_all.append(keypoints)

cap.release()

# í‰ê·  í¬ì¦ˆ ë²¡í„° ì‚¬ìš©
if keypoints_all:
    avg_keypoints = np.mean(keypoints_all, axis=0).reshape(1, -1)
    prediction = clf.predict(avg_keypoints)
    print(f'ğŸ¯ ì˜ˆì¸¡ëœ í–‰ë™: {prediction[0]}')
else:
    print("âŒ ì˜ìƒì—ì„œ í¬ì¦ˆë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
